# The Google File System

## 3 系统交互

原则：最小化和 Master 节点的交互

### 3.1 租约(lease)和变更顺序

租约：主 Chunk 节点向 Master 申请的时长

写入操作控制流：

1. 客户端请求主 Chunk 节点和其他副本位置
2. 客户端接收信息并缓存
3. 客户机推送数据
4. 副本确认接收后，客户机向主 Chunk 发送请求，并记录更新状态，分配序列号

<img src="../images/image-20210930194027935.png" alt="image-20210930194027935" style="zoom:67%;" />

### 3.2 数据流

利用基于 TCP 连接的、管道式数据推送方式来最小化延迟

### 3.3 原子的记录追加

记录追加：一种修改操作。客户机把数据推送给文件最后一个 Chunk 的所有副本，之后发送请求给主 Chunk<!--？怎么做到的？-->

### 3.4 快照

1. 取消快照需要文件的 Chunk 的租约
2. 快照和源文件指向相同的 Chunk 地址
3. 快照操作后，客户机需要写入 Chunk 时，需要检查并复制 Chunk

## 4 Master 节点的操作

### 4.1 命名空间和锁

- GFS 的命名空间：一个全路径和元数据映射关系的查找表
- 不支持文件或者目录的链接（即 Unix 术语中的硬链接或者符号链接）
- Master 节点操作之前需要获取对应各级目录和文件（读或写）锁

优点：支持对同一目录的并行操作。eg：在同一目录下创建多个文件，需要获取目录的读取锁和文件的写入锁。

### 4.2 副本的位置

典型的拓扑结构：有数百个 Chunk 服务器安装在许多机架上

条件：不同机架上的两台机器间的通讯可能跨越一个或多个网络交换机、机架的出入带宽可能比机架内所有机器加和在一起的带宽 要小

目标：最大化数据可靠性和可用性，最大化网络带宽利用率

解决：在多个机架间分布储存 Chunk 的副本

优点：网络流量方面，对 Chunk 的读操作，能够有效利用多个机架的整合带宽。

缺点：写操作必须和多个机架上的设备进行网络通信

### 4.3 创建，重新复制，重新负载均衡

Master 节点需要考虑多个因素进行 Chunk 的布置：

- 平衡 Chunk 服务器之间的硬盘使用率：在低于平均硬盘使用率的 Chunk 服务器上存储新的副本
- 控制大量的写入数据的操作：限制在每个 Chunk 服务器上 latest 的 Chunk 创建操作的次数

因此，Chunk 副本需要分布在不同机架上

### 4.4 垃圾回收

惰性策略，不立即回收可用的物理内存

**机制**：定时常规扫描时删除

Chunk 的引用容易获取：都存储在 Master 服务器的映射表

Chunk 的副本容易获取：以 Linux 文件的形式存储在 Chunk 服务器

**所有 Master 节点不能识别的副本都是 垃圾**

## 5 容错和诊断

### 5.1 高可用性

**快速恢复**：

Master 和 Chunk 服务器可以在数秒内恢复状态并重新启动<!--？怎么做到的？-->

**复制**

- Chunk 节点复制
- Master 节点复制：复制所有的操作日志和 checkpoint 文件
- 影子 Master 节点：在 Master 服务器宕机的时候提 供文件系统的只读访问。数据更新比 Master 慢(1s内)

### 5.2 数据完整性

Chunk 服务器：独立维护 Checksum 检查数据是否损坏

### 5.3 诊断工具

尽可能保存详尽的、深入细节的诊断日志

顺序异步写入日志





